{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b9c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beea9896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad87796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_length=2 max_length=15 count=32033\n"
     ]
    }
   ],
   "source": [
    "min_length = min(len(w) for w in words)\n",
    "max_length = max(len(w) for w in words)\n",
    "count = len(words)\n",
    "print(f'{min_length=} {max_length=} {count=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e484095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = ['.'] + sorted(list(set(''.join(words))))\n",
    "ALPHABET_SIZE = len(characters)\n",
    "N = torch.zeros((ALPHABET_SIZE, ALPHABET_SIZE), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531a064e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr_to_index = {s:i for i,s in enumerate(characters)}\n",
    "index_to_chr = {i:s for i,s in enumerate(characters)}\n",
    "\n",
    "class StoiMapper(object):\n",
    "    def __getitem__(self, key):\n",
    "        return chr_to_index[key[0]] * ALPHABET_SIZE + chr_to_index[key[1]]\n",
    "\n",
    "\n",
    "class ItosMapper(object):\n",
    "    def __getitem__(self, key):\n",
    "        return index_to_chr[key // ALPHABET_SIZE] + index_to_chr[key % ALPHABET_SIZE]\n",
    "\n",
    "stoi = StoiMapper()\n",
    "itos = ItosMapper()\n",
    "stoi['aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a88296e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training set of all the bigrams\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.', '.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        x_index = stoi[ch1 + ch2]\n",
    "        y_index = chr_to_index[ch3]\n",
    "        xs.append(x_index)\n",
    "        ys.append(y_index)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349be19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=ALPHABET_SIZE ** 2).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28b452d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 729])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "125a2596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5674, -0.2373, -0.0274,  ..., -0.0707,  2.4968,  2.4448],\n",
       "        [ 0.4724,  1.4830,  0.3175,  ..., -0.4275, -2.1259,  0.9604],\n",
       "        [ 0.1275,  1.7862,  0.9084,  ..., -0.0410,  0.4848, -0.9423],\n",
       "        ...,\n",
       "        [ 0.5146, -1.0181, -1.2665,  ..., -1.0288,  0.5508, -1.0114],\n",
       "        [-0.9299,  0.3116,  1.3902,  ...,  2.1475,  1.6333,  1.9126],\n",
       "        [-0.5997,  0.4037, -0.3309,  ..., -0.5076, -2.0352, -0.1582]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((ALPHABET_SIZE ** 2, ALPHABET_SIZE), generator=g, requires_grad=True)\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "748d49bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.279918909072876\n",
      "2.2796058654785156\n",
      "2.2792952060699463\n",
      "2.278986692428589\n",
      "2.2786805629730225\n",
      "2.278376817703247\n",
      "2.2780747413635254\n",
      "2.2777748107910156\n",
      "2.2774770259857178\n",
      "2.277181625366211\n",
      "2.276887893676758\n",
      "2.2765963077545166\n",
      "2.2763068675994873\n",
      "2.27601957321167\n",
      "2.2757339477539062\n",
      "2.2754502296447754\n",
      "2.2751686573028564\n",
      "2.274888515472412\n",
      "2.274610996246338\n",
      "2.274334669113159\n",
      "2.2740607261657715\n",
      "2.2737886905670166\n",
      "2.2735178470611572\n",
      "2.2732491493225098\n",
      "2.272982120513916\n",
      "2.272716999053955\n",
      "2.272453784942627\n",
      "2.2721922397613525\n",
      "2.2719321250915527\n",
      "2.2716739177703857\n",
      "2.2714173793792725\n",
      "2.271162271499634\n",
      "2.270909070968628\n",
      "2.2706573009490967\n",
      "2.2704074382781982\n",
      "2.2701587677001953\n",
      "2.269912004470825\n",
      "2.2696666717529297\n",
      "2.269422769546509\n",
      "2.2691807746887207\n",
      "2.268939971923828\n",
      "2.26870059967041\n",
      "2.268462896347046\n",
      "2.2682266235351562\n",
      "2.2679922580718994\n",
      "2.26775860786438\n",
      "2.267526626586914\n",
      "2.267296314239502\n",
      "2.2670674324035645\n",
      "2.2668395042419434\n",
      "2.266613245010376\n",
      "2.266388416290283\n",
      "2.266165018081665\n",
      "2.2659428119659424\n",
      "2.2657217979431152\n",
      "2.2655022144317627\n",
      "2.2652840614318848\n",
      "2.2650668621063232\n",
      "2.2648515701293945\n",
      "2.2646372318267822\n",
      "2.2644238471984863\n",
      "2.264212131500244\n",
      "2.2640016078948975\n",
      "2.263792037963867\n",
      "2.2635841369628906\n",
      "2.2633771896362305\n",
      "2.2631711959838867\n",
      "2.2629668712615967\n",
      "2.262763500213623\n",
      "2.2625608444213867\n",
      "2.262359857559204\n",
      "2.262160062789917\n",
      "2.2619614601135254\n",
      "2.261763572692871\n",
      "2.2615673542022705\n",
      "2.261371612548828\n",
      "2.2611773014068604\n",
      "2.260983943939209\n",
      "2.260791778564453\n",
      "2.2606005668640137\n",
      "2.2604103088378906\n",
      "2.260221481323242\n",
      "2.26003360748291\n",
      "2.2598469257354736\n",
      "2.2596607208251953\n",
      "2.2594759464263916\n",
      "2.259291887283325\n",
      "2.2591090202331543\n",
      "2.2589271068573\n",
      "2.2587461471557617\n",
      "2.25856614112854\n",
      "2.258387327194214\n",
      "2.258209466934204\n",
      "2.2580320835113525\n",
      "2.2578561305999756\n",
      "2.257680892944336\n",
      "2.257506847381592\n",
      "2.257333278656006\n",
      "2.2571609020233154\n",
      "2.2569894790649414\n"
     ]
    }
   ],
   "source": [
    "learning_rate = -100\n",
    "# gradient descent\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=ALPHABET_SIZE ** 2).float()\n",
    "    logits = xenc @ W # log-counts\n",
    "    loss = F.cross_entropy(logits, ys) + 0.001 * (W**2).mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += learning_rate * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b0d83ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misabrucheneviwozeluchinitalqujaaquprhezasinarahelilelalaumalameroluolimalyumi.\n",
      "gadoadamazocanananolorakhelladabhaborhemadaxruxanelivisufazahujoqumananozreyusinanisisavitrelivaluyaleroyuquwauxisadayalanoledalenememamamanilizalozevazakalemanazyroloxtorojoavatodanosharyivarokanimanevaishelaucanatinakrelueloralunalyumaro.\n",
      "jarodelatikanadaroshaemadanarufinarhavasyaravilelevamumabelinangraroadezyoqusalujadelespedoryoladedanabryaninoshamarasaocaremazhehalosurolondemaluvaelazishelelivizetralevanelizalarelalumalabraholinoluxtrumunotyakezastatyatanilelananahanajadelixqbavevamalamaosowelomyeyareirishayogrorhamarhastomanasariscladocrolomomaniyadalitazuorutraivememadamidadakicouralemuroxayauzabralomilhofrouflayososanalasaryasuomelyianyamemazecrilamaralomcotelesilayadelanyaamesedanocrorarirelurelaasyaremaladelalanamesarileustanaloshaalamakamivalelulaylikaphellalezaninanakelevitadalanifodadaveselolarakedemalizelanirmalurozyamasanorozabemchilalaeliroletalufrazabraledanemesarogelemaxchanavizevalamisulurogelopauviadanilywemanalyuzaleloadizyowinitzimahakrmanaloanavemyonyoleushabajuchythaxpranilarocomosanamalofaroloumcxidashaspraeyuzatebemaramalavaaqkalyurolevinyhaarishuyadaadqudizelizelelofrmavlelyarevelolezadelunokahazanelelishanaryosharorodabrevimalurarelyolarodelyesagrezayolbrayemanohanelaspevidelelilucoraridaaamarazufhamamadaxzakalalimaraurarorelegvastinyelauynonarushelisrfalogabavishaisucanekoalarzyazyadrelolyelugosamayoamolyiquemanayamanarosiluinanodazu.\n",
      "alalolerotaanap.\n",
      "janashaairamadrujalirimisoloremironomozizeakanelatavakayageradarizamadvelololyeanaaviwurarhulioselemeserelapalayosabradloastasuhadau.\n",
      "yabelowisyamilemaleshalijanemayadelyouhamaranemavquremidinnamanaroleaxarozanevimevidemyelolisharelemadaairyaniveyamalemcochadrelardavisalamaranaluvelirempograzanamamamabroloryanifaenaumavuchelidetasunelinadashayamireseshavirotrdaryaaranamelemakaimalasucadevamalivivanevarolenolanezuzizenamayamaacovefishananhasasyadenistrevilalwcchasolelunirililuluvelyemachanizadamarelyaulisauminiminodaralelikisaadelyijemanavazeluzishalaravedhisenabraukavelemyuoleixqwilumizhedaaliunochezyomabolianimamavarananiloneavaabrayopahalebrhazyolemolayadaveisimyaziryurahamaedayavilemalelymuloakabevislitarhaquosabreranaisemopasuwomemzeveskiharamareselozananiminananinasanishtrolufa.\n",
      "joraluwyzashisogulutamabevyevirolizalayalelelakailamalalarochepulevamyavanomelelifxiyelayaomememadatroleanyumaushaabralartjauemegremonnyyistaselolyeminemottolotelayufeskanelesuzravanyvelityanishurubreinalexarabrgrelasavmanaginelayaiyadanyuinamachesanedvizurilyutiselusalemaloeskautorhezumadelasoromaketolaruufaravaacalavaradalyudalemanbrelaufrulelufaauyabroasousumavayoxemizarolalaroqu.\n",
      "izusegazisistadisayuwremolemisuryumaregadabaemanoanamamarishanailabomabryalyuobrananyesu.\n",
      "mayolakholelimabaamcozishelayanaredalorodelutoloruisuradahorerakanilodaizamaliuxfi.\n",
      "daharuzilelalabriyaririshanelayayelalasisanamaishaunyphabryaligisamizyodanelabodrevademishaabejesrezopofevasananatajasalaiyimaraladerazamabrelayeabruradelelanulalaqqugrunamaliseenyabrataastelemamasarahelyoavarulirdenyanyanaviyaniyelazemaxf.\n",
      "damasheenemilirelilu.\n",
      "amahalastetananiwimishanyaashelanahabaroriredegraemailyeyaleloradelosyauuzalayoglyolishadaamisezu.\n",
      "kemozilabradarapaemelangelujaprabarizanonyimalelelerahademayuflademithadakalilolanasamavabrarutazagushanilarololanitrolelyoloradinanemacolemivmemitrzeliranemaloliromiyoroamyaireralirivelameluniluvizyakadayoeimelelilaluwhanyucatesehuzavamisivwelamylayeclanolimanowaveremelurizyjamanesemitabrelaqufasalyalrolinalenamabrareliidenisoshalesuzaluyadamivaviraleyalabunetrayxilolararinadtkokofotadimalivanitalevinanavyeluramanirareisegbromaatanemurevilaretyanaiyufxyarhailivamaninebotaneastalalashayolemezayamitabrazadoalakahavqyayuryotyareviniiharanfasalidelelaelelitaufaliroelatrairoaladaimcheishaujeralarhalisosinolasu.\n",
      "kahpremaniavabelifamarajotamalonaleuhamadi.\n",
      "juuxanamevisitalaumanlalayouctaxyanalemakrizeluibrofemoloanazazyuyocamalilaniziviselyatyokaviasifamyazalavashamasyfemowyuistolesifamanaleschelereasinabelufaisyolumilelosyanelariralyasanavaleloluiqubazyaitisomamalishesurdalavikanelzalemananachastarinadraamakamitiyolereraubemamadevimaxahaiyyayevaramaqphalelemanyashumazesadrelereliremoalanisareleivelalganizanikanyayahaivakastolirivananevibrhabruyazanoimeishadevizanonoantinadadayaqureshanisarurasolyavivakamapranyelevaededisyugushuwavuyaelisanivionemoudesauyavamanasanivivisustineinasusiranilolalanarovisakizadanilivinilesrelisavamavaremomivadeluzathazhucaraiscolbrasinaelizoskemanaezenalelayaswamaalastamalyaaraavauyadyauranolodemalumamanezaaalafanocotavareviroaninemazoakavadleloanorolataroriskemimanelarileyoaavaradunevonosanisaliufjaisyaakascaaromanayelalayavinelisalyomaloderazamamabelarakelelbrauniveniluchamopanapomalyarairatedushalosadsudalunamaasaralelolalunwamoterelepelyaraufryonivalahyalainarolu.\n",
      "varirhelakolyanostazadailexcaronabradelanaranobriuivelelaaayadesolyanimadelanevizoshaanemalaliluliyamizanaemimifiemalizianolisistaleluneladaisidagutakakosiboadhadumolaniufisanayanaisumayusaniranoluofelilavinozarulezytaranemamaviqufetaarumamadyamanolelelisilolyeseyuclemuchanabrhaanyazolaisulurelorele.\n",
      "jamyulanonimabraromihilikrhelajeluckemazywiavizaleinamaevivananalisinamemasudesadenushanizadeemaralilyuwalariravizishaizhmaalalivalevkevelauaxjalonolyoleimalulaladanimazanilaroranyuzaxigrronavivauzanazaraloryelyeluskanuelademalisanosaamalikareilivkoleraleleleschanoamkhauralyolaleyeizanaviyavfrharolrememalaxemyolufemabolororelanavqulizedareesucauaspadaalorfelaneilidilolyaibrodroranezyufotyouzelaadalolelorarelatradinyomiyaranemolaarazunoweliisaluizetreowinomyjorolemaazyetaenoninacofroroduziteushadwavfrolelizfanyarizalelahanalinishelanotomelholaganaryeblofaiakanizezodaberilamiliryabrolavizufelimayuvityurazufranivisaremilimapafadavemixfralagidasinanalilixivalelutyamanishuiroh.\n",
      "shaashaairomakateralelararolemouzazabamayamadelilelyxzelasivpanalelarivaiyazodosumanaevezaroutyalemyarisanyalanpeevilirazyahadwneararonalyavayolyasavistanalirhabroreluizaninelavanalelumayosarzedadilfbrizaalwaromememenami.\n",
      "sibelililanabeiraliyenobosholatadavavemizakinelunamadrulayavizalulabremaibyimanotzafesmisulevmorimalwyuwihostaurikhivakaimanyiskolaneiemolasanorilishozamiluyuqucolisalolemauzaevevanomamaraarolanyavaneryarusezademanaxayuivadalizyulutoletihaemasyoroninanivakedochcamaruiproshomamaseziyoleryiseviradevavinevu.\n",
      "kaxaramahalnalabrananogolarilyoskarhtyolauzeizaranenazanaahogivavelistimufemeimaunamiychaaableviremyailanocolunyalaryaufaeizkawirobrhaunistayosaresilyiducaquyalyoryrohalerusoledevaranitatazolidadedahbradpauonabesharuzaakizohajarizimabririmarojvaroczurivrizalenanaleuqumalalaviryablelalowhisogekromu.\n"
     ]
    }
   ],
   "source": [
    "# sample neural net\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=ALPHABET_SIZE**2).float()\n",
    "        logits = xenc @ W\n",
    "        p = logits.exp()\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        new_letter = index_to_chr[ix]\n",
    "        out.append(new_letter)\n",
    "        if new_letter == '.':\n",
    "            break\n",
    "    print(''.join(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "266f1d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0976322591304779"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = W[stoi['ad']].exp()\n",
    "x /= x.sum()\n",
    "x[chr_to_index['.']].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aace3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learnings\n",
    "# - One hot is useful for categorical data\n",
    "# - Loss function of NLL is useful for categorical data as opposed to MSE for regression\n",
    "# - Softmax is useful for categorical data\n",
    "\n",
    "# Questions:\n",
    "# Q: Why is the learning rate value negative?\n",
    "# A: Because we are trying to minimize the loss function, and the gradient is pointing in the direction of the steepest ascent.\n",
    "#    So we need to go in the opposite direction.\n",
    "# Q: What is -0.1 a reasonable learning rate?\n",
    "\n",
    "# counting loss 2.45\n",
    "# nn loss 2.46"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
